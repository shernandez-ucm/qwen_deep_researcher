**AI Adoption, Usage, and Expectations in Higher Education**

| Theme | Key Findings | Representative Sources |
|-------|--------------|------------------------|
| **Drivers of AI Adoption** | • **Perceived usefulness** and **ease of use** are the strongest predictors of whether faculty and students decide to adopt AI tools (TAM). <br>• **Trust** in the technology’s reliability and data‑privacy safeguards, as well as **social influence** (peer and institutional endorsement), significantly boost adoption rates. <br>• **Personal innovativeness** and **external motivation** (e.g., curriculum mandates, competitive advantage) further accelerate uptake. | 1, 2, 3 |
| **Patterns of AI Usage** | • Overall usage remains **moderate** but is on an upward trajectory, especially in disciplines that can directly leverage AI for practice (e.g., Endodontics, Periodontics). <br>• In many STEM and health‑science programs, AI is used primarily for data analysis, simulation, and personalized learning, but the depth of integration varies widely. | 4, 5 |
| **Student and Faculty Expectations** | • **Positive expectations**: improved academic performance, more efficient research workflows, and enhanced critical‑thinking skills. <br>• **Cautious optimism**: many educators anticipate AI’s potential to transform assessment and feedback but remain wary of over‑reliance. | 6, 7 |
| **Concerns and Barriers** | • **Reliability & validity**: doubts about algorithmic bias, data quality, and the reproducibility of AI‑generated results. <br>• **Ethical & originality issues**: fears that AI may compromise academic integrity or diminish students’ creative engagement. <br>• **Integration challenges**: lack of institutional support, insufficient training, and limited interoperability with existing LMS and research tools. | 8, 9, 10 |

### Synthesis

1. **Adoption is driven by a mix of cognitive (usefulness, ease of use) and social (trust, influence) factors**. The TAM/SDT framework shows that while intrinsic motivation matters, external pressures and peer norms often tip the balance toward adoption.  
2. **Usage is currently moderate but growing**. In fields where AI offers clear, tangible benefits (e.g., clinical simulations, data‑heavy research), uptake is higher. Across the board, however, many educators still use AI only in isolated tasks rather than as a core component of teaching or research.  
3. **Expectations are largely optimistic**—faculty and students see AI as a catalyst for higher‑order learning and research efficiency. Yet this optimism is tempered by **concerns about algorithmic bias, academic integrity, and the risk of superficial engagement**.  
4. **Barriers are largely practical and ethical**. Even when faculty are willing to adopt, they often lack the training, resources, or institutional policies needed to embed AI meaningfully into curricula and research workflows.

**Implication for Institutions**  
To move from moderate to high‑impact AI integration, universities should:  
- Strengthen **trust‑building mechanisms** (transparent algorithms, robust data‑privacy policies).  
- Provide **targeted training** that aligns with faculty’s personal innovativeness and the specific needs of their disciplines.  
- Foster **peer‑led communities of practice** to amplify social influence and share best‑practice case studies.  
- Address **ethical and originality concerns** through clear guidelines and academic‑integrity safeguards.  

By aligning these drivers, usage patterns, and expectations, higher‑education institutions can create a more supportive ecosystem that encourages responsible, effective, and transformative AI adoption.