["* AcademAI: Investigating AI Usage, Attitudes, and Literacy in Higher Education and Research : https://www.semanticscholar.org/paper/4337f66bb5d0fcbcf71235a4e08c06b7eb374947\n* The Impact of Generative AI on Student Engagement and Ethics in Higher Education : https://www.semanticscholar.org/paper/238411b81e1c97d09e8d31e1b196459883384948\n* Generative AI in Higher Education: Analyzing Adoption Patterns and Perceptions in Agriculture and Natural Resources Courses : https://www.semanticscholar.org/paper/d1c347867dca65a9dc204d39e75bcd36d491033c\n* I don't trust you (anymore)! - The effect of students' LLM use on Lecturer-Student-Trust in Higher Education : https://www.semanticscholar.org/paper/603e864fbf2c5bf16cf0ffea3ad20dfc8e75d770\n* Validating the ChatGPT Usage Scale: psychometric properties and factor structures among postgraduate students : https://www.semanticscholar.org/paper/d9ade2970c876da92e5295b01e1fcb9d5b7403f2\n* Generative AI : https://www.semanticscholar.org/paper/b402f607e392e663650248989f874773f067f017\n* A Comparison of Human‐Written Versus AI‐Generated Text in Discussions at Educational Settings: Investigating Features for ChatGPT, Gemini and BingAI : https://www.semanticscholar.org/paper/2619ed36f26052e6bd18f253a3731c7114c778a0\n* Perception, usage, and concerns of artificial intelligence applications among postgraduate dental students: cross-sectional study : https://www.semanticscholar.org/paper/48a09982c04fd91ad7669d48ff61a47bcc500cee\n* Comparing AI-Assisted and Traditional Teaching in College English: Pedagogical Benefits and Learning Behaviors : https://www.semanticscholar.org/paper/d1ac9b20c1f49fc948657a1c534da4eacea52279\n* Understanding University Students' Adoption of ChatGPT: Insights from TAM, SDT, and Beyond : https://www.semanticscholar.org/paper/505f430311353214084f39686c59794898926981"]4["Sources:\n\nSource: AcademAI: Investigating AI Usage, Attitudes, and Literacy in Higher Education and Research\n===\nURL: https://www.semanticscholar.org/paper/4337f66bb5d0fcbcf71235a4e08c06b7eb374947\n===\nMost relevant content from source: We investigate perceptions of AI among university students and staff, focusing on sociodemographic predictors of use, attitudes and literacy. We follow an explanatory mixed-methods approach: an online survey (269 students and staff) capturing self-reported AI use, attitudes, and literacy, and 24 semi-structured online interviews exploring barriers to acceptance in higher education and research. Quantitative data reveal differences in perceptions of AI usage between students and staff. Males report higher use, more positive attitudes, and greater AI literacy than females. Higher socioeconomic status predicts more frequent use, and older age predicts lower AI literacy. Qualitative findings highlight concerns about academic repercussions of AI and threat to jobs. Participants highlight a lack of guidance and need for support to promote responsible use. Universities should increase engagement, and provide unambiguous guidance, to tackle misperceptions of how AI is used by others and address staff and student fears impacting AI acceptance and adoption.\n===\nFull source content limited to 1000 tokens: We investigate perceptions of AI among university students and staff, focusing on sociodemographic predictors of use, attitudes and literacy. We follow an explanatory mixed-methods approach: an online survey (269 students and staff) capturing self-reported AI use, attitudes, and literacy, and 24 semi-structured online interviews exploring barriers to acceptance in higher education and research. Quantitative data reveal differences in perceptions of AI usage between students and staff. Males report higher use, more positive attitudes, and greater AI literacy than females. Higher socioeconomic status predicts more frequent use, and older age predicts lower AI literacy. Qualitative findings highlight concerns about academic repercussions of AI and threat to jobs. Participants highlight a lack of guidance and need for support to promote responsible use. Universities should increase engagement, and provide unambiguous guidance, to tackle misperceptions of how AI is used by others and address staff and student fears impacting AI acceptance and adoption.\n\nSource: The Impact of Generative AI on Student Engagement and Ethics in Higher Education\n===\nURL: https://www.semanticscholar.org/paper/238411b81e1c97d09e8d31e1b196459883384948\n===\nMost relevant content from source: The rapid adoption of Artificial Intelligence (AI) in higher education is reshaping students’ learning experiences, with tools such as ChatGPT, Grammarly, and Microsoft Copilot becoming integral to academic work. This study, informed by data from the Digital Education Council Global AI Student Survey 2024, examines the impact of AI on students, focusing on usage patterns, trust in AI-generated content, ethical awareness, and expectations for institutional support. Findings indicate that 86% of students use AI for various academic tasks, with a majority expressing concerns about trust, fairness, and over-reliance on AI. While students value AI’s benefits, only 5% are fully aware of institutional guidelines on AI use, and 72% desire more AI literacy courses, reflecting a significant need for comprehensive support in navigating AI responsibly. The study underscores the importance of clear ethical guidelines, faculty training, and student involvement in AI policy formation to foster responsible AI use and preserve academic integrity. These insights offer valuable guidance for educators and policymakers seeking to integrate AI ethically and effectively into higher education.\n===\nFull source content limited to 1000 tokens: The rapid adoption of Artificial Intelligence (AI) in higher education is reshaping students’ learning experiences, with tools such as ChatGPT, Grammarly, and Microsoft Copilot becoming integral to academic work. This study, informed by data from the Digital Education Council Global AI Student Survey 2024, examines the impact of AI on students, focusing on usage patterns, trust in AI-generated content, ethical awareness, and expectations for institutional support. Findings indicate that 86% of students use AI for various academic tasks, with a majority expressing concerns about trust, fairness, and over-reliance on AI. While students value AI’s benefits, only 5% are fully aware of institutional guidelines on AI use, and 72% desire more AI literacy courses, reflecting a significant need for comprehensive support in navigating AI responsibly. The study underscores the importance of clear ethical guidelines, faculty training, and student involvement in AI policy formation to foster responsible AI use and preserve academic integrity. These insights offer valuable guidance for educators and policymakers seeking to integrate AI ethically and effectively into higher education.\n\nSource: Generative AI in Higher Education: Analyzing Adoption Patterns and Perceptions in Agriculture and Natural Resources Courses\n===\nURL: https://www.semanticscholar.org/paper/d1c347867dca65a9dc204d39e75bcd36d491033c\n===\nMost relevant content from source: This study investigates empirical data on how students and educators perceive the use of generative artificial intelligence (AI) in agriculture and natural resources (ANR) courses. By surveying participants at a land-grant university, the research explores how different educational backgrounds and sociodemographic factors influence attitudes toward AI adoption. The findings reveal that less than half of the respondents currently use generative AI, with significantly lower usage among first-year and rural students. Key drivers encouraging AI adoption include perceived academic benefits, ease of use, and familiarity with the technology. In contrast, barriers such as concerns about reliability, potential misuse, and information overload deter usage. Seniors and graduate students are more likely to embrace generative AI tools, whereas older and rural students show lower adoption rates. The Analytical Hierarchical Process underscores the necessity for tailored strategies to address specific concerns like inaccurate information and how to leverage AI's advantages, such as streamlining tasks for instructors and providing grammar assistance for students. Future course curricula and institutional policies should incorporate targeted training and additional support to meet specific educational needs, thereby enhancing learning outcomes and ensuring equitable access to the benefits of generative AI tools.\n===\nFull source content limited to 1000 tokens: This study investigates empirical data on how students and educators perceive the use of generative artificial intelligence (AI) in agriculture and natural resources (ANR) courses. By surveying participants at a land-grant university, the research explores how different educational backgrounds and sociodemographic factors influence attitudes toward AI adoption. The findings reveal that less than half of the respondents currently use generative AI, with significantly lower usage among first-year and rural students. Key drivers encouraging AI adoption include perceived academic benefits, ease of use, and familiarity with the technology. In contrast, barriers such as concerns about reliability, potential misuse, and information overload deter usage. Seniors and graduate students are more likely to embrace generative AI tools, whereas older and rural students show lower adoption rates. The Analytical Hierarchical Process underscores the necessity for tailored strategies to address specific concerns like inaccurate information and how to leverage AI's advantages, such as streamlining tasks for instructors and providing grammar assistance for students. Future course curricula and institutional policies should incorporate targeted training and additional support to meet specific educational needs, thereby enhancing learning outcomes and ensuring equitable access to the benefits of generative AI tools.\n\nSource: I don't trust you (anymore)! - The effect of students' LLM use on Lecturer-Student-Trust in Higher Education\n===\nURL: https://www.semanticscholar.org/paper/603e864fbf2c5bf16cf0ffea3ad20dfc8e75d770\n===\nMost relevant content from source: Trust plays a pivotal role in lecturer-student collaboration, encompassing teaching and research aspects. The advent of Large Language Models (LLMs)in platforms like Open AI’s ChatGPT, coupled with their cost-effectiveness and high-quality results, has led to their rapid adoption among university students. However, discerning genuine student input from LLM-generated output poses a challenge for lecturers. This dilemma jeopardizes the trust relationship between lecturers and students, potentially impacting university downstream activities, particularly collaborative research initiatives. Despite attempts to establish guidelines for student LLM use, a clear framework that is mutually beneficial for lecturers and students in higher education remains elusive. This study addresses the research question: How does the use of LLMs by students impact informational Procedural Justice, influencing Team Trust and Expected team performance? Methodically, we applied a quantitative construct-based survey, evaluated using techniques of Structural Equation Modelling (PLSSEM)to examine potential relationships among these constructs. Our findings based on 23 valid respondents from Ndejje University indicate that lecturers are less concerned about the fairness of LLM use per se but are more focused on the transparency of student utilization, which significantly influences Team Trust positively. This research contributes to the global discourse on integrating and regulating LLMs and subsequent models in education. We propose that guidelines should support LLM use while enforcing transparency in lecturer-student collaboration to foster Team Trust and Performance. The study contributes valuable insights for shaping policies enabling ethical and transparent LLMs usage in education to ensure the effectiveness of collaborative learning environments.\n===\nFull source content limited to 1000 tokens: Trust plays a pivotal role in lecturer-student collaboration, encompassing teaching and research aspects. The advent of Large Language Models (LLMs)in platforms like Open AI’s ChatGPT, coupled with their cost-effectiveness and high-quality results, has led to their rapid adoption among university students. However, discerning genuine student input from LLM-generated output poses a challenge for lecturers. This dilemma jeopardizes the trust relationship between lecturers and students, potentially impacting university downstream activities, particularly collaborative research initiatives. Despite attempts to establish guidelines for student LLM use, a clear framework that is mutually beneficial for lecturers and students in higher education remains elusive. This study addresses the research question: How does the use of LLMs by students impact informational Procedural Justice, influencing Team Trust and Expected team performance? Methodically, we applied a quantitative construct-based survey, evaluated using techniques of Structural Equation Modelling (PLSSEM)to examine potential relationships among these constructs. Our findings based on 23 valid respondents from Ndejje University indicate that lecturers are less concerned about the fairness of LLM use per se but are more focused on the transparency of student utilization, which significantly influences Team Trust positively. This research contributes to the global discourse on integrating and regulating LLMs and subsequent models in education. We propose that guidelines should support LLM use while enforcing transparency in lecturer-student collaboration to foster Team Trust and Performance. The study contributes valuable insights for shaping policies enabling ethical and transparent LLMs usage in education to ensure the effectiveness of collaborative learning environments.\n\nSource: Validating the ChatGPT Usage Scale: psychometric properties and factor structures among postgraduate students\n===\nURL: https://www.semanticscholar.org/paper/d9ade2970c876da92e5295b01e1fcb9d5b7403f2\n===\nMost relevant content from source: Background The rapid adoption of ChatGPT in academic settings has raised concerns about its impact on learning, research, and academic integrity. This study aimed to develop and validate a comprehensive ChatGPT Usage Scale specifically tailored to postgraduate students, addressing the need for a psychometrically sound instrument to assess the multidimensional nature of ChatGPT usage in higher education. Methods A cross-sectional survey design was employed, involving 443 postgraduate students from two Egyptian universities. The initial 39-item scale underwent Exploratory Factor Analysis (EFA) using principal component analysis with Varimax rotation. Confirmatory Factor Analysis (CFA) was conducted to assess the model fit and psychometric properties of the final 15-item measure. Internal consistency reliability was evaluated using Cronbach’s alpha and McDonald’s omega. Results EFA revealed a three-factor structure explaining 49.186% of the total variance: Academic Writing Aid (20.438%), Academic Task Support (14.410%), and Reliance and Trust (14.338%). CFA confirmed the three-factor structure with acceptable fit indices (χ2(87)\u2009=\u2009223.604, p\u2009<\u2009.001; CMIN/DF\u2009=\u20092.570; CFI\u2009=\u20090.917; TLI\u2009=\u20090.900; RMSEA\u2009=\u20090.060). All standardized factor loadings were statistically significant (p\u2009<\u2009.001), ranging from 0.434 to 0.728. The scale demonstrated good internal consistency (Cronbach’s α\u2009=\u20090.848, McDonald’s ω\u2009=\u20090.849) and composite reliability (CR\u2009=\u20090.855). The average variance extracted (AVE) was 0.664, supporting convergent validity. Conclusions The validated ChatGPT Usage Scale provides a reliable and valid instrument for assessing postgraduate students’ engagement with ChatGPT across multiple dimensions. This tool offers valuable insights into AI-assisted academic practices, enabling more nuanced investigations into the effects of ChatGPT on postgraduate education.\n===\nFull source content limited to 1000 tokens: Background The rapid adoption of ChatGPT in academic settings has raised concerns about its impact on learning, research, and academic integrity. This study aimed to develop and validate a comprehensive ChatGPT Usage Scale specifically tailored to postgraduate students, addressing the need for a psychometrically sound instrument to assess the multidimensional nature of ChatGPT usage in higher education. Methods A cross-sectional survey design was employed, involving 443 postgraduate students from two Egyptian universities. The initial 39-item scale underwent Exploratory Factor Analysis (EFA) using principal component analysis with Varimax rotation. Confirmatory Factor Analysis (CFA) was conducted to assess the model fit and psychometric properties of the final 15-item measure. Internal consistency reliability was evaluated using Cronbach’s alpha and McDonald’s omega. Results EFA revealed a three-factor structure explaining 49.186% of the total variance: Academic Writing Aid (20.438%), Academic Task Support (14.410%), and Reliance and Trust (14.338%). CFA confirmed the three-factor structure with acceptable fit indices (χ2(87)\u2009=\u2009223.604, p\u2009<\u2009.001; CMIN/DF\u2009=\u20092.570; CFI\u2009=\u20090.917; TLI\u2009=\u20090.900; RMSEA\u2009=\u20090.060). All standardized factor loadings were statistically significant (p\u2009<\u2009.001), ranging from 0.434 to 0.728. The scale demonstrated good internal consistency (Cronbach’s α\u2009=\u20090.848, McDonald’s ω\u2009=\u20090.849) and composite reliability (CR\u2009=\u20090.855). The average variance extracted (AVE) was 0.664, supporting convergent validity. Conclusions The validated ChatGPT Usage Scale provides a reliable and valid instrument for assessing postgraduate students’ engagement with ChatGPT across multiple dimensions. This tool offers valuable insights into AI-assisted academic practices, enabling more nuanced investigations into the effects of ChatGPT on postgraduate education.\n\nSource: Generative AI\n===\nURL: https://www.semanticscholar.org/paper/b402f607e392e663650248989f874773f067f017\n===\nMost relevant content from source: This paper reports preliminary findings from an ongoing, campus wide research project on effective methods for generative AI applicability in pursuit of effective and engaging teaching and learning activities. Generative AI has had a tremendous adoption rate since the public release of ChatGPT 3.5 on November 30th 2022. This has necessitated that educators and administrators consider the potential opportunities and threats usage of generative AI by students and faculty may have on higher education. Recognizing the inevitability of generative AI, the researchers have proposed a university-wide research project to ascertain the changes in faculty and students perspectives when using generative AI The research project is two-fold. First, a longitudinal survey has been developed to address research questions about usage and perceptions of generative AI change over time.\nThe second prong of this research project focuses on the implementation of new and continuing generative AI professional development workshops. These “AI Institutes” are targeted educational opportunities to provide faculty, staff, and students with hands-on experiences that model appropriate ways to teach and learn with generative AI tools. Workshops change based on audience needs, but will be designed to support such processes as introductory and advanced lessons on building learning activities which engage students with generative AI, administrative shortcuts, best practices for writing, and our university’s AI policy and principles.\nThe longitudinal survey, thus, allows the research team to gauge changes in perspectives as the “AI Institutes'' are deployed and widespread adoption of generative AI tools become more mainstream. This paper reports on the first year of this research project, including one survey and one AI Institute.\nThis research on integrating generative AI technologies into teaching and learning has important implications for the field of networked learning. As the paper explores, rapid advances in AI are changing how students and faculty interact with content and each other. Findings from the longitudinal survey and AI Institutes could provide insights into how to thoughtfully leverage these emerging tools to enhance connections, dialogue, collaboration, and co-creation of knowledge within digital learning networks.\xa0\nWhile further research is needed, this project takes an important first step in assessing faculty and student perceptions that can inform appropriate AI integration. Lessons learned could guide other institutions exploring the potentials and pitfalls of weaving generative AI into networked learning ecosystems.\n===\nFull source content limited to 1000 tokens: This paper reports preliminary findings from an ongoing, campus wide research project on effective methods for generative AI applicability in pursuit of effective and engaging teaching and learning activities. Generative AI has had a tremendous adoption rate since the public release of ChatGPT 3.5 on November 30th 2022. This has necessitated that educators and administrators consider the potential opportunities and threats usage of generative AI by students and faculty may have on higher education. Recognizing the inevitability of generative AI, the researchers have proposed a university-wide research project to ascertain the changes in faculty and students perspectives when using generative AI The research project is two-fold. First, a longitudinal survey has been developed to address research questions about usage and perceptions of generative AI change over time.\nThe second prong of this research project focuses on the implementation of new and continuing generative AI professional development workshops. These “AI Institutes” are targeted educational opportunities to provide faculty, staff, and students with hands-on experiences that model appropriate ways to teach and learn with generative AI tools. Workshops change based on audience needs, but will be designed to support such processes as introductory and advanced lessons on building learning activities which engage students with generative AI, administrative shortcuts, best practices for writing, and our university’s AI policy and principles.\nThe longitudinal survey, thus, allows the research team to gauge changes in perspectives as the “AI Institutes'' are deployed and widespread adoption of generative AI tools become more mainstream. This paper reports on the first year of this research project, including one survey and one AI Institute.\nThis research on integrating generative AI technologies into teaching and learning has important implications for the field of networked learning. As the paper explores, rapid advances in AI are changing how students and faculty interact with content and each other. Findings from the longitudinal survey and AI Institutes could provide insights into how to thoughtfully leverage these emerging tools to enhance connections, dialogue, collaboration, and co-creation of knowledge within digital learning networks.\xa0\nWhile further research is needed, this project takes an important first step in assessing faculty and student perceptions that can inform appropriate AI integration. Lessons learned could guide other institutions exploring the potentials and pitfalls of weaving generative AI into networked learning ecosystems.\n\nSource: A Comparison of Human‐Written Versus AI‐Generated Text in Discussions at Educational Settings: Investigating Features for ChatGPT, Gemini and BingAI\n===\nURL: https://www.semanticscholar.org/paper/2619ed36f26052e6bd18f253a3731c7114c778a0\n===\nMost relevant content from source: Generative artificial intelligence (GenAI) models, such as ChatGPT, Gemini, and BingAI, have become integral to educational sciences, bringing about significant transformations in the education system and the processes of knowledge production. These advancements have facilitated new methods of teaching, learning, and information dissemination. However, the widespread adoption of these technologies raises serious concerns about academic ethics, content authenticity, and the potential for misuse in academic settings. This study aims to evaluate the linguistic features and differences between AI‐generated and human‐generated articles in educational contexts. By analysing various linguistic attributes such as singular word usage, sentence lengths, and the presence of repetitive or stereotypical phrases, the study identifies key distinctions between the two types of content. The findings indicate that human‐generated articles exhibit higher average singular word usage and longer sentence lengths compared to AI‐generated articles, suggesting a more complex and nuanced language structure in human writing. Furthermore, the study employs ensemble learning models, including Random Forest, Gradient Boosting, AdaBoost, Bagging, and Extra Trees, to classify and distinguish between AI‐generated and human‐generated texts. Among these, the Extra Trees model achieved the highest classification accuracy of 93%, highlighting its effectiveness in identifying AI‐generated content. Additionally, experiments using the BERTurk model, a transformer‐based language model, demonstrated a classification accuracy of 95%, particularly in distinguishing human‐generated articles from those produced by Gemini. The results of this study have significant implications for the future of education, as they underscore the critical need for robust tools and methodologies to differentiate between human and AI‐generated content.\n===\nFull source content limited to 1000 tokens: Generative artificial intelligence (GenAI) models, such as ChatGPT, Gemini, and BingAI, have become integral to educational sciences, bringing about significant transformations in the education system and the processes of knowledge production. These advancements have facilitated new methods of teaching, learning, and information dissemination. However, the widespread adoption of these technologies raises serious concerns about academic ethics, content authenticity, and the potential for misuse in academic settings. This study aims to evaluate the linguistic features and differences between AI‐generated and human‐generated articles in educational contexts. By analysing various linguistic attributes such as singular word usage, sentence lengths, and the presence of repetitive or stereotypical phrases, the study identifies key distinctions between the two types of content. The findings indicate that human‐generated articles exhibit higher average singular word usage and longer sentence lengths compared to AI‐generated articles, suggesting a more complex and nuanced language structure in human writing. Furthermore, the study employs ensemble learning models, including Random Forest, Gradient Boosting, AdaBoost, Bagging, and Extra Trees, to classify and distinguish between AI‐generated and human‐generated texts. Among these, the Extra Trees model achieved the highest classification accuracy of 93%, highlighting its effectiveness in identifying AI‐generated content. Additionally, experiments using the BERTurk model, a transformer‐based language model, demonstrated a classification accuracy of 95%, particularly in distinguishing human‐generated articles from those produced by Gemini. The results of this study have significant implications for the future of education, as they underscore the critical need for robust tools and methodologies to differentiate between human and AI‐generated content.\n\nSource: Perception, usage, and concerns of artificial intelligence applications among postgraduate dental students: cross-sectional study\n===\nURL: https://www.semanticscholar.org/paper/48a09982c04fd91ad7669d48ff61a47bcc500cee\n===\nMost relevant content from source: Background Future dental applications of artificial intelligence (AI) are anticipated to be widely adopted across all dental specialities. However, there are some concerns among many users about the accuracy of the given information. Therefore, this study aimed to investigate postgraduate’ dental students’ perception, usage, and concerns towards AI systems’ applications. Materials and methods An online self-administered survey, consisting of 19 closed-ended questions in the English language, and a 3-point Likert-type scale was used to obtain a simple and straightforward response from participants in a “forced-choice” response format that was distributed to postgraduate dental students in the faculty of dentistry of multiple Universities. Results Younger participants and BDS holders are more likely to use AI-based software (p\u2009<\u20090.001), as well as showing more optimism about AI’s potential to advance dentistry, whereas PhD holders are more skeptical about its integral role in healthcare (p\u2009<\u20090.001). Speciality influenced AI adoption significantly, with Endodontics showing the highest percentage (52.4% for 1\u2009+\u2009years of AI usage; p\u2009=\u20090.006). Concerns about AI reliability and originality in research vary significantly by level of education and Speciality (p\u2009<\u20090.05). Younger participants show greater belief in AI’s potential for major advancements in dentistry (p\u2009<\u20090.001). Conclusions Postgraduate dental students generally perceive AI positively, recognizing its potential to enhance care. Usage remains moderate, with higher adoption in specialities like Endodontics and Periodontics. Concerns include AI’s accuracy, ethical implications, and integration challenges, highlighting the need for further education and research. Clinical trial number Not applicable. Supplementary Information The online version contains supplementary material available at 10.1186/s12909-025-07544-6.\n===\nFull source content limited to 1000 tokens: Background Future dental applications of artificial intelligence (AI) are anticipated to be widely adopted across all dental specialities. However, there are some concerns among many users about the accuracy of the given information. Therefore, this study aimed to investigate postgraduate’ dental students’ perception, usage, and concerns towards AI systems’ applications. Materials and methods An online self-administered survey, consisting of 19 closed-ended questions in the English language, and a 3-point Likert-type scale was used to obtain a simple and straightforward response from participants in a “forced-choice” response format that was distributed to postgraduate dental students in the faculty of dentistry of multiple Universities. Results Younger participants and BDS holders are more likely to use AI-based software (p\u2009<\u20090.001), as well as showing more optimism about AI’s potential to advance dentistry, whereas PhD holders are more skeptical about its integral role in healthcare (p\u2009<\u20090.001). Speciality influenced AI adoption significantly, with Endodontics showing the highest percentage (52.4% for 1\u2009+\u2009years of AI usage; p\u2009=\u20090.006). Concerns about AI reliability and originality in research vary significantly by level of education and Speciality (p\u2009<\u20090.05). Younger participants show greater belief in AI’s potential for major advancements in dentistry (p\u2009<\u20090.001). Conclusions Postgraduate dental students generally perceive AI positively, recognizing its potential to enhance care. Usage remains moderate, with higher adoption in specialities like Endodontics and Periodontics. Concerns include AI’s accuracy, ethical implications, and integration challenges, highlighting the need for further education and research. Clinical trial number Not applicable. Supplementary Information The online version contains supplementary material available at 10.1186/s12909-025-07544-6.\n\nSource: Comparing AI-Assisted and Traditional Teaching in College English: Pedagogical Benefits and Learning Behaviors\n===\nURL: https://www.semanticscholar.org/paper/d1ac9b20c1f49fc948657a1c534da4eacea52279\n===\nMost relevant content from source: In the era of artificial intelligence, higher education is embracing new opportunities for pedagogical innovation. This study investigates the impact of integrating AI into college English teaching, focusing on its role in enhancing students’ critical thinking and academic engagement. A controlled experiment compared AI-assisted instruction with traditional teaching, revealing that AI-supported learning improved overall English proficiency, especially in writing skills and among lower- and intermediate-level learners. Behavioral analysis showed that the quality of AI interaction—such as meaningful feedback adoption and autonomous revision—was more influential than mere usage frequency. Student feedback further suggested that AI-enhanced teaching stimulated motivation and self-efficacy while also raising concerns about potential overreliance and shallow engagement. These findings highlight both the promise and the limitations of AI in language education, underscoring the importance of teacher facilitation and thoughtful design of human–AI interaction to support deep and sustainable learning.\n===\nFull source content limited to 1000 tokens: In the era of artificial intelligence, higher education is embracing new opportunities for pedagogical innovation. This study investigates the impact of integrating AI into college English teaching, focusing on its role in enhancing students’ critical thinking and academic engagement. A controlled experiment compared AI-assisted instruction with traditional teaching, revealing that AI-supported learning improved overall English proficiency, especially in writing skills and among lower- and intermediate-level learners. Behavioral analysis showed that the quality of AI interaction—such as meaningful feedback adoption and autonomous revision—was more influential than mere usage frequency. Student feedback further suggested that AI-enhanced teaching stimulated motivation and self-efficacy while also raising concerns about potential overreliance and shallow engagement. These findings highlight both the promise and the limitations of AI in language education, underscoring the importance of teacher facilitation and thoughtful design of human–AI interaction to support deep and sustainable learning.\n\nSource: Understanding University Students' Adoption of ChatGPT: Insights from TAM, SDT, and Beyond\n===\nURL: https://www.semanticscholar.org/paper/505f430311353214084f39686c59794898926981\n===\nMost relevant content from source: Aim/Purpose: The aim of this study is to explore the factors that influence higher education students’ adoption of ChatGPT by incorporating constructs from the Technology Acceptance Model (TAM) and Self-Determination Theory (SDT) with trust, social influence, and personal innovativeness.\n\nBackground: Even though the use of ChatGPT has become more popular among university students, there is no clear evidence about the reasons that would make them adopt or abstain from using such a tool.\n\nMethodology: The study utilized a survey that was answered by 150 university students registered in the faculty of engineering at a public university. The survey was developed by Google Forms and focused on how useful and easy they think ChatGPT is, their motivations, trust, social influence, innovativeness, and their readiness to use it. Statistical analysis was performed using SPSS 26 and Smart-PLS4, with the latter being particularly useful due to the study’s complex model and adherence to sample size criteria.\n\nContribution: This research provides fresh insights into how students perceive and start using modern AI tools like ChatGPT. It also helps educators and policymakers understand how to integrate AI technologies into education better to make learning more effective.\n\nFindings: The study reveals that students are more likely to adopt ChatGPT if they perceive it as useful and easy to use. External motivation and social influence significantly impact students’ behavioral intentions to use ChatGPT, while trust also plays a crucial role. Intrinsic motivation, however, does not significantly affect behavioral intention. The strongest predictor of actual use is behavioral intention, indicating that students who intend to use ChatGPT are highly likely to do so. Personal innovativeness is another significant factor influencing both behavioral intention and actual use. \n\nRecommendations for Practitioners: Educators and policymakers should focus on enhancing the perceived usefulness, ease of use, trust, social influence, and innovativeness related to ChatGPT to increase its adoption in educational settings.\n\nRecommendation for Researchers: Future research should explore additional psychological and contextual factors that may influence the adoption of ChatGPT and other similar technologies among students.\n\nImpact on Society: Understanding the factors that influence the adoption of ChatGPT can help in developing strategies to integrate such tools effectively in education, potentially improving learning outcomes and digital literacy among students.\n\nFuture Research: Further studies should examine the long-term effects of ChatGPT usage on students’ learning outcomes and investigate the adoption patterns in different educational contexts and disciplines.\n\n\n===\nFull source content limited to 1000 tokens: Aim/Purpose: The aim of this study is to explore the factors that influence higher education students’ adoption of ChatGPT by incorporating constructs from the Technology Acceptance Model (TAM) and Self-Determination Theory (SDT) with trust, social influence, and personal innovativeness.\n\nBackground: Even though the use of ChatGPT has become more popular among university students, there is no clear evidence about the reasons that would make them adopt or abstain from using such a tool.\n\nMethodology: The study utilized a survey that was answered by 150 university students registered in the faculty of engineering at a public university. The survey was developed by Google Forms and focused on how useful and easy they think ChatGPT is, their motivations, trust, social influence, innovativeness, and their readiness to use it. Statistical analysis was performed using SPSS 26 and Smart-PLS4, with the latter being particularly useful due to the study’s complex model and adherence to sample size criteria.\n\nContribution: This research provides fresh insights into how students perceive and start using modern AI tools like ChatGPT. It also helps educators and policymakers understand how to integrate AI technologies into education better to make learning more effective.\n\nFindings: The study reveals that students are more likely to adopt ChatGPT if they perceive it as useful and easy to use. External motivation and social influence significantly impact students’ behavioral intentions to use ChatGPT, while trust also plays a crucial role. Intrinsic motivation, however, does not significantly affect behavioral intention. The strongest predictor of actual use is behavioral intention, indicating that students who intend to use ChatGPT are highly likely to do so. Personal innovativeness is another significant factor influencing both behavioral intention and actual use. \n\nRecommendations for Practitioners: Educators and policymakers should focus on enhancing the perceived usefulness, ease of use, trust, social influence, and innovativeness related to ChatGPT to increase its adoption in educational settings.\n\nRecommendation for Researchers: Future research should explore additional psychological and contextual factors that may influence the adoption of ChatGPT and other similar technologies among students.\n\nImpact on Society: Understanding the factors that influence the adoption of ChatGPT can help in developing strategies to integrate such tools effectively in education, potentially improving learning outcomes and digital literacy among students.\n\nFuture Research: Further studies should examine the long-term effects of ChatGPT usage on students’ learning outcomes and investigate the adoption patterns in different educational contexts and disciplines."]